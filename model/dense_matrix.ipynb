{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jiangruiyin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import utils\n",
    "from keras.preprocessing import sequence \n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/jiangruiyin/Desktop/proj/data_cleaned(1).csv\"\n",
    "data = pd.read_csv(path, header=None, names=['lyrics', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data.iloc[:,1]\n",
    "lyrics = data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sólo una palabra se hubiera llevado el dolor con el beso amargo de aquel licor hubiera bastado mi amor sólo una mentira se viene conmigo a pasear sentirme querida en aquel abrazo en el mar  con el vestido azul que un día conociste me marcho sin saber si me besaste antes de irte te di mi corazón y tú lo regalaste te di todo el amor que pude darte y me robaste he rasgado mi vestido con una copa de vino hoy tu amor corta como el cristal  en el cielo hay playas donde ves la vida pasar donde los recuerdos no hacen llorar vienen muy despacio y se van sólo una caricia me hubiera ayudado a olvidar que no eran mis labios los que ahora te hacen soñar  con el vestido azul que un día conociste me marcho sin saber si me besaste antes de irte te di mi corazón y tú lo regalaste te di todo el amor que pude darte y me robaste he rasgado mi vestido con una copa de vino hoy tu amor corta como el cristal buena suerte en tu camino yo ya tengo mi destino con mi sangre escribo este final'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics[2462]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_word(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text_split =  tokenizer.tokenize(text)\n",
    "    #text_word = [w for w in text_split if w.isalpha()] \n",
    "    return [w for w in text_split if w.isalpha()] \n",
    "\n",
    "def rm_stopwords(text):\n",
    "    stop_words_EN = stopwords.words('english')\n",
    "    stop_words_SP = stopwords.words('spanish')\n",
    "    stop_words = stop_words_EN + stop_words_SP\n",
    "    return [w for w in text if not w in stop_words]\n",
    "\n",
    "def preprocess_text(texts):\n",
    "    data = []\n",
    "    for text in texts:\n",
    "        t_split = split_word(text)\n",
    "        t_rmstop = rm_stopwords(t_split)\n",
    "        data.append(t_rmstop)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "texts = preprocess_text(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628\n"
     ]
    }
   ],
   "source": [
    "print(max(len(t) for t in texts))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer(num_words=dim)\n",
    "token.fit_on_texts(texts)\n",
    "xtrain = token.texts_to_matrix(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2464, 500)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = utils.to_categorical(labels, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2464, 4)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xtrain, ytrain, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Conv2D, MaxPooling2D \n",
    "from keras.layers import Flatten,Embedding,SimpleRNN\n",
    "from keras.optimizers import SGD, Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1000, activation='relu', input_dim=dim))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(120, activation='relu', input_dim=dim))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(4, activation='sigmoid'))\n",
    "\n",
    "#Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1971/1971 [==============================] - 3s 2ms/step - loss: 1.3768 - accuracy: 0.2933\n",
      "Epoch 2/20\n",
      "1971/1971 [==============================] - 2s 1ms/step - loss: 1.3491 - accuracy: 0.3521\n",
      "Epoch 3/20\n",
      "1971/1971 [==============================] - 2s 1ms/step - loss: 1.3233 - accuracy: 0.3582\n",
      "Epoch 4/20\n",
      "1971/1971 [==============================] - 2s 1ms/step - loss: 1.2909 - accuracy: 0.4196\n",
      "Epoch 5/20\n",
      "1971/1971 [==============================] - 2s 1ms/step - loss: 1.2386 - accuracy: 0.5099\n",
      "Epoch 6/20\n",
      "1971/1971 [==============================] - 2s 1ms/step - loss: 1.1612 - accuracy: 0.5870\n",
      "Epoch 7/20\n",
      "1971/1971 [==============================] - 2s 1ms/step - loss: 1.0441 - accuracy: 0.6509\n",
      "Epoch 8/20\n",
      "1971/1971 [==============================] - 2s 1ms/step - loss: 0.9324 - accuracy: 0.6834\n",
      "Epoch 9/20\n",
      "1971/1971 [==============================] - 2s 1ms/step - loss: 0.8296 - accuracy: 0.7128\n",
      "Epoch 10/20\n",
      "1971/1971 [==============================] - 2s 1ms/step - loss: 0.7323 - accuracy: 0.7468\n",
      "Epoch 11/20\n",
      "1971/1971 [==============================] - 2s 1ms/step - loss: 0.6493 - accuracy: 0.7620\n",
      "Epoch 12/20\n",
      "1971/1971 [==============================] - 3s 1ms/step - loss: 0.5979 - accuracy: 0.7879\n",
      "Epoch 13/20\n",
      "1971/1971 [==============================] - 2s 1ms/step - loss: 0.5497 - accuracy: 0.8097\n",
      "Epoch 14/20\n",
      "1971/1971 [==============================] - 2s 1ms/step - loss: 0.4930 - accuracy: 0.8250\n",
      "Epoch 15/20\n",
      "1971/1971 [==============================] - 2s 1ms/step - loss: 0.4605 - accuracy: 0.8346\n",
      "Epoch 16/20\n",
      "1971/1971 [==============================] - 3s 1ms/step - loss: 0.3985 - accuracy: 0.8691\n",
      "Epoch 17/20\n",
      "1971/1971 [==============================] - 2s 1ms/step - loss: 0.3860 - accuracy: 0.8635\n",
      "Epoch 18/20\n",
      "1971/1971 [==============================] - 2s 1ms/step - loss: 0.3531 - accuracy: 0.8747\n",
      "Epoch 19/20\n",
      "1971/1971 [==============================] - 3s 1ms/step - loss: 0.3251 - accuracy: 0.8904\n",
      "Epoch 20/20\n",
      "1971/1971 [==============================] - 3s 1ms/step - loss: 0.2960 - accuracy: 0.9107\n"
     ]
    }
   ],
   "source": [
    "his = model.fit(X_train, y_train, epochs=20, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493/493 [==============================] - 0s 512us/step\n",
      "Test accuracy: 0.726166307926178\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test,verbose=1)\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN1 = Sequential()\n",
    "CNN1.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "CNN1.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "CNN1.add(Flatten())\n",
    "CNN1.add(Dense(512, activation='sigmoid'))\n",
    "CNN1.add(Dense(512, activation='sigmoid'))\n",
    "CNN1.add(Dense(10, activation='softmax'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
